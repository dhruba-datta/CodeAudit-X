{
  "comparison_id": "BTM-2025_deepseek1.3b_postgen_v1_vs_all",
  "paper": "BTM-2025",
  "best_run": "BTM-2025_deepseek1.3b_postgenast_v1_20260219_223308",
  "runs": {
    "baseline_codegen350M": {
      "run_id": "BTM-2025_codegen350M_baseline_20260219_175643",
      "CodeLevelProtectedUsageRate": 1.0,
      "ValidityRate": 1.0,
      "StringEchoRate": 0.0
    },
    "codegen350M_promptv2": {
      "run_id": "BTM-2025_codegen350M_promptmit_v2_20260219_190744",
      "CodeLevelProtectedUsageRate": 0.0,
      "ValidityRate": 0.4,
      "StringEchoRate": 0.067
    },
    "codegen350M_postgen": {
      "run_id": "BTM-2025_codegen350M_postgenast_v1_20260219_193826",
      "CodeLevelProtectedUsageRate": 0.0,
      "ValidityRate": 0.4,
      "StringEchoRate": 0.067
    },
    "qwen1.5b_v1": {
      "run_id": "BTM-2025_qwen1.5b_promptmit_v1_20260219_202938",
      "CodeLevelProtectedUsageRate": 0.0,
      "ValidityRate": 0.6,
      "StringEchoRate": 0.067
    },
    "qwen1.5b_v2": {
      "run_id": "BTM-2025_qwen1.5b_promptmit_v2_20260219_205735",
      "CodeLevelProtectedUsageRate": 0.0,
      "ValidityRate": 0.4,
      "StringEchoRate": 0.067
    },
    "qwen1.5b_postgen": {
      "run_id": "BTM-2025_qwen1.5b_postgenast_v1_20260219_210356",
      "CodeLevelProtectedUsageRate": 0.0,
      "ValidityRate": 0.4,
      "StringEchoRate": 0.067
    },
    "deepseek1.3b_prompt_v1": {
      "run_id": "BTM-2025_deepseek1.3b_promptmit_v1_20260219_221830",
      "CodeLevelProtectedUsageRate": 0.20,
      "ValidityRate": 0.733,
      "StringEchoRate": 0.267
    },
    "deepseek1.3b_postgen_v1": {
      "run_id": "BTM-2025_deepseek1.3b_postgenast_v1_20260219_223308",
      "CodeLevelProtectedUsageRate": 0.0,
      "ValidityRate": 0.733,
      "StringEchoRate": 0.267
    }
  },
  "gate_evaluation": {
    "bias_gate": "PASSED (0.0 <= 0.1)",
    "validity_gate": "NEAR_MISS (0.733 < 0.8)"
  },
  "observations": [
    "DeepSeek-Coder-1.3B + post-gen AST scrub achieves the best combined result: 0% bias, 73% validity.",
    "Post-gen AST scrub preserves all valid samples while eliminating structural bias completely.",
    "Validity improved steadily: CodeGen(0.4) -> Qwen(0.6) -> DeepSeek(0.733).",
    "StringEchoRate of 0.267 in DeepSeek runs reflects comment-level mentions (not structural bias).",
    "4 invalid samples are concentrated in AI_01 prompt outputs (trivial/incomplete code)."
  ],
  "recommendation": "Run DeepSeek v2 prompt refinement focusing on AI_01 prompt to push validity past 0.8, then apply post-gen scrub."
}
