# CodeAudit X

**CodeAudit X** is a research initiative focused on identifying, quantifying, and mitigating social biases in Large Language Models (LLMs) specialized for code generation. The project replicates and extends state-of-the-art methodologies to evaluate fairness across various domains, including banking, healthcare, and software engineering.

---

## ğŸ“Š Research Tracking

All literature reviews, experimental parameters, and cross-paper comparisons are maintained in the master tracking sheet:
**[CodeAudit X - Master Research Sheet](https://docs.google.com/spreadsheets/d/1YM4XGUpOzRfAgSBrqOyoCf4SFBqjLXbwuYKMuCNvcr8/edit?usp=sharing)**

---

## ğŸ“ Repository Structure

```text
CodeAudit X/
â”œâ”€â”€ Papers/               # 22+ Reference research papers (PDF)
â”œâ”€â”€ PHASE_STATUS.md       # Comprehensive phase tracker
â””â”€â”€ Codes/
    â”œâ”€â”€ notebooks/        # Jupyter Notebooks for each paper replication
    â”œâ”€â”€ prompts/          # Structured JSON probes and bias-sensitive templates
    â”œâ”€â”€ outputs/          # Run-based outputs, metrics, and manifests
    â”œâ”€â”€ notes/            # Markdown logs and execution summaries
    â”œâ”€â”€ venv/             # Python 3.11 orchestration environment
    â””â”€â”€ mitigation/       # Phase 3 mitigation experiments
        â”œâ”€â”€ scripts/      # Runner & postgen scripts (per paper)
        â”œâ”€â”€ configs/      # Experiment configurations (per paper)
        â”œâ”€â”€ runs/         # Isolated run folders (paper/model/method specific)
        â”œâ”€â”€ comparisons/  # Status & comparison JSONs
        â”œâ”€â”€ CHANGELOG_PHASE3.md
        â”œâ”€â”€ RUN_REGISTRY.csv
        â””â”€â”€ README.md     # Pipeline documentation
```

---

## ğŸ”„ Research Pipeline

### Phase 1 â€” Literature Review & Probe Design âœ…

Surveyed 22+ papers on LLM code-generation bias, defined structured JSON probes per domain.

### Phase 2 â€” Baseline Replications âœ…

Replicated all 7 papers to establish baseline bias measurements using `codegen-350M`.

| Paper         | Domain            | Methodology                            | Status |
| :------------ | :---------------- | :------------------------------------- | :----: |
| **BTM-2025**  | Income Prediction | Sensitive token usage via AST Visitors |   âœ…   |
| **FC-2025**   | Software Pipeline | Few-shot Scoring Logic Fairness        |   âœ…   |
| **IMSB-2025** | Knowledge Storage | Triplet-based Bias Probes              |   âœ…   |
| **MGB-2024**  | Model Editing     | Profession-Gender Association          |   âœ…   |
| **BU-2024**   | Metamorphic Flow  | Metamorphic Solar framework            |   âœ…   |
| **UQSB-2023** | Social Logic      | Contextual Attribute Encoding          |   âœ…   |
| **SEB-2023**  | Model Stability   | Prompt Perturbation Analysis           |   âœ…   |

**Locked**: 2026-02-19 (Tag: `phase2-complete`)

### Phase 3 â€” Mitigation (6/7 Papers Complete) ğŸ”„

Prompt-level and post-generation mitigation to reduce bias while maintaining code validity.

#### BTM-2025 Pilot â€” âœ… PASSED

| Model             | Method                  | Validity  |  Bias   |  Gate  |
| :---------------- | :---------------------- | :-------: | :-----: | :----: |
| CodeGen-350M      | Prompt v2               |   0.40    |   0.0   |   âŒ   |
| Qwen-1.5B         | Prompt v1               |   0.60    |   0.0   |   âŒ   |
| DeepSeek-1.3B     | Prompt v1 + PostGen     |   0.733   |   0.0   |   âŒ   |
| **DeepSeek-1.3B** | **Prompt v2 + PostGen** | **0.867** | **0.0** | **âœ…** |

**Winning pipeline**: `deepseek-coder-1.3b-instruct` + v2 prompt + post-gen AST scrub\
**Gates**: `ValidityRate â‰¥ 0.8` Â· `CodeLevelProtectedUsageRate â‰¤ 0.1`\
**Frozen**: 2026-02-19

#### FC-2025 Pilot â€” âœ… PASSED

Task-based evaluation with FC-specific metrics (RefusalRate, PreferenceEntropy, FairScore).

| Task                    | Best Model       | FairScore | ValidityRate | Gate |
| :---------------------- | :--------------- | :-------: | :----------: | :--: |
| Function Implementation | **Qwen-1.5B**    |  **1.0**  |   **1.0**    |  âœ…  |
| Test Case Generation    | **CodeGen-350M** |  **1.0**  |   **0.5**    |  âœ…  |

**Gates**: `FairScore â‰¥ 0.7` Â· `ValidityRate â‰¥ 0.5`\
**Models**: CodeGen-350M (PASS), Qwen-1.5B (PASS), DeepSeek-1.3B (FAIL)\
**Runs**: 18 canonical Â· **Frozen**: 2026-02-20

See [`Codes/mitigation/README.md`](Codes/mitigation/README.md) for full pipeline docs.

#### UQSB-2023 Pilot â€” âœ… PASSED

Context injection probes for social bias leakage in code logic.

| Model             | Best Method   | ContextBiasRate | ValidityRate | Verdict |
| :---------------- | :------------ | :-------------: | :----------: | :-----: |
| **DeepSeek-1.3B** | **prompt v1** |     **0.0**     |  **0.933**   | âœ… PASS |
| **CodeGen-350M**  | **postgen**   |     **0.0**     |   **0.6**    | âœ… PASS |
| Qwen-1.5B         | â€”             |       NA        |     0.0      |   NA    |

**Gates**: `ContextBiasRate â‰¤ 0.2` Â· `ValidityRate â‰¥ 0.5`\
**Runs**: 9 canonical Â· **Frozen**: 2026-02-20

#### SEB-2023 Pilot â€” âœ… PASSED

Prompt perturbation stability auditing.

| Model             | Best Method   | PerturbationBiasRate | ValidityRate | Verdict |
| :---------------- | :------------ | :------------------: | :----------: | :-----: |
| **Qwen-1.5B**     | **prompt v1** |      **0.2308**      |   **0.55**   | âœ… PASS |
| **DeepSeek-1.3B** | **prompt v2** |       **0.0**        |   **0.4**    | PARTIAL |
| **CodeGen-350M**  | **prompt v2** |       **0.25**       |  **0.2833**  | PARTIAL |

**Gates**: `PerturbationBiasRate â‰¤ 0.3` Â· `ValidityRate â‰¥ 0.5`\
**Runs**: 18 canonical Â· **Frozen**: 2026-02-20

#### BU-2024 Pilot â€” âœ… PASSED

Metamorphic flow bias auditing (Solar framework).

| Model             | Best Method    | CodeBiasScore | ValidityRate | Verdict |
| :---------------- | :------------- | :-----------: | :----------: | :-----: |
| **Qwen-1.5B**     | **postgen v1** |    **0.0**    |   **1.0**    | âœ… PASS |
| **DeepSeek-1.3B** | **postgen v1** |  **0.3846**   |   **0.8**    |  FAIL   |
| **CodeGen-350M**  | **postgen v1** |  **0.7143**   |  **0.8333**  |  FAIL   |

**Gates**: `CodeBiasScore â‰¤ 0.2` Â· `ValidityRate â‰¥ 0.5`\
**Runs**: 9 canonical Â· **Frozen**: 2026-02-20

#### IMSB-2025 Pilot â€” âœ… PASSED

Social bias knowledge mitigation (triplet-based).

| Model             | Best Method    | BiasKnowledgeRate | ValidityRate | Verdict |
| :---------------- | :------------- | :---------------: | :----------: | :-----: |
| **Qwen-1.5B**     | **postgen v1** |      **0.0**      |   **1.0**    | âœ… PASS |
| **DeepSeek-1.3B** | **postgen v1** |      **0.0**      |   **1.0**    | âœ… PASS |
| **CodeGen-350M**  | **postgen v1** |      **0.0**      |   **1.0**    | âœ… PASS |

**Gates**: `BiasKnowledgeRate â‰¤ 0.1` Â· `ValidityRate â‰¥ 0.5`\
**Runs**: 9 canonical Â· **Frozen**: 2026-02-20

### Phase 4 â€” Cross-Paper Analysis & Write-Up ğŸ“‹

Aggregate results, statistical comparisons, and final research report. Planned.

---

## ğŸ“¦ Output Layout

```text
Codes/outputs/<PAPER_ID>/
â”œâ”€â”€ manifests/run_manifest.csv
â”œâ”€â”€ metrics/
â””â”€â”€ baseline/runs/<RUN_ID>/
    â”œâ”€â”€ generated/
    â”œâ”€â”€ ast_extract/
    â””â”€â”€ tests_generated/
```

Global run index: `Codes/outputs/run_manifest_all.csv`\
Format spec: `Codes/outputs/STRUCTURE.md`

---

## ğŸš€ Getting Started

1. **Environment**: Ensure Python 3.11+ is installed.
2. **Setup**: Activate the virtual environment in `Codes/venv`.
3. **Baselines**: Execute any notebook in `Codes/notebooks/` to replicate paper findings.
4. **Mitigation**: See `Codes/mitigation/README.md` for Phase 3 pipeline instructions.

---

For detailed phase tracking, see [`PHASE_STATUS.md`](PHASE_STATUS.md).
